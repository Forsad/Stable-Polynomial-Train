{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath('../src')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import wandb\n",
    "key = None\n",
    "if key is not None:\n",
    "    wandb.login(key=key)\n",
    "    os.environ['WANDB_API_KEY'] = key\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"capture24.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 23 01:30:39 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           Off |   00000000:06:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             58W /  300W |   19220MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "fol = \"data/capture24/\"\n",
    "Y = np.load(fol + 'Y_Walmsley2020.npy')\n",
    "T = np.load(fol + 'T.npy')\n",
    "P = np.load(fol + 'P.npy')\n",
    "X_feats = pd.read_pickle(fol + 'X_feats.pkl').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['light' 'moderate-vigorous' 'sedentary' 'sleep']\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Y to int labels from string labels\n",
    "mp = {y: i for i, y in enumerate(np.unique(Y))}\n",
    "Y = np.array([mp[y] for y in Y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'light': 0, 'moderate-vigorous': 1, 'sedentary': 2, 'sleep': 3} {0: 'light', 1: 'moderate-vigorous', 2: 'sedentary', 3: 'sleep'}\n"
     ]
    }
   ],
   "source": [
    "reverse_mp = {i: y for y, i in mp.items()}\n",
    "print(mp, reverse_mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(934762, 32) (934762,) (934762,) (934762,)\n"
     ]
    }
   ],
   "source": [
    "print(X_feats.shape, Y.shape, T.shape, P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,) (32,)\n"
     ]
    }
   ],
   "source": [
    "# do test train val split by subject\n",
    "import torch\n",
    "def custom_train_test_split(P, test_size=0.1, random_state=42):\n",
    "    #get all unique subjects\n",
    "    P_unique = np.unique(P)\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    tot = len(P_unique)\n",
    "    test_size = int(tot * test_size)\n",
    "    train_size = tot - test_size    \n",
    "    train_subjects = rng.choice(P_unique, train_size, replace=False)\n",
    "    test_subjects = np.setdiff1d(P_unique, train_subjects)\n",
    "    train_ids = np.where(np.isin(P, train_subjects))[0]\n",
    "    test_ids = np.where(np.isin(P, test_subjects))[0]\n",
    "    return train_ids, test_ids\n",
    "\n",
    "#do train test split by subject\n",
    "train_ids, test_ids = custom_train_test_split(P, test_size=0.1, random_state=42)\n",
    "#Also do a validation split by subject\n",
    "train_ids, val_ids = custom_train_test_split(train_ids, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train, y_train, P_train = X_feats[train_ids], Y[train_ids], P[train_ids]\n",
    "X_test, y_test, P_test = X_feats[test_ids], Y[test_ids], P[test_ids]\n",
    "X_val, y_val, P_val = X_feats[val_ids], Y[val_ids], P[val_ids]\n",
    "\n",
    "def normalize_data(X):\n",
    "    X_mean = X.mean(axis=0)\n",
    "    X_std = X.std(axis=0)\n",
    "    return (X - X_mean) / X_std, X_mean, X_std\n",
    "\n",
    "X_train, X_train_mean, X_train_std = normalize_data(X_train)\n",
    "print(X_train_mean.shape, X_train_std.shape)\n",
    "X_test = (X_test - X_train_mean) / X_train_std\n",
    "X_val = (X_val - X_train_mean) / X_train_std\n",
    "\n",
    "train_set = torch.utils.data.TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "test_set = torch.utils.data.TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
    "val_set = torch.utils.data.TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762288 87776 84698\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set), len(test_set), len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type             | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | model          | MLP              | 54.5 K | train\n",
      "1 | base_criterion | CrossEntropyLoss | 0      | train\n",
      "2 | criterion      | CustomPolyLoss   | 0      | train\n",
      "------------------------------------------------------------\n",
      "54.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "54.5 K    Total params\n",
      "0.218     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B 20 samp_size 100 initialization least_square pol_degree 4\n",
      "B 20 samp_size 100 initialization least_square pol_degree 4\n",
      "B 20 samp_size 100 initialization least_square pol_degree 4\n",
      "B 20 samp_size 100 initialization least_square pol_degree 4\n",
      "B 20 samp_size 100 initialization least_square pol_degree 4\n",
      "B 20 samp_size 100 initialization least_square pol_degree 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed20286fca1b45d1bbe4ec74620aa02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c779c3193c9c4b96963e27aacf15302a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0eaeee1b69424098f6551a97e773ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d182fd39f340d588f0a8ef6108edda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bde744cc0504d77bfb614904add79c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5faea8958e4f8ebceb331adadb0eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4728f7f3aaf14a14949fdc425e47e49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49d2adf5eb04304994ea386044cd9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde771520e584f038155b42650d125bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486ef7d153fd4532ab1b57201661d3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65ce9302f974a6ebea9e214cdbf8bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ec169a4bbb4406be0261fa226dc133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /code/Polynomial-NN/notebooks/lightning_logs/version_40/checkpoints/best-acc-epoch=7-val_acc=0.00.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /code/Polynomial-NN/notebooks/lightning_logs/version_40/checkpoints/best-acc-epoch=7-val_acc=0.00.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4666c238364550a76f7f06dee66777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /code/Polynomial-NN/notebooks/lightning_logs/version_40/checkpoints/best-acc-epoch=7-val_acc=0.00.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /code/Polynomial-NN/notebooks/lightning_logs/version_40/checkpoints/best-acc-epoch=7-val_acc=0.00.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      Validate metric               DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       val_acc_epoch             0.7656969428062439\n",
      "  val_boundary_loss_epoch        28.75305938720703\n",
      "val_cross_entropy_loss_epoch     288.1406555175781\n",
      "       val_loss_epoch            288.1406555175781\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253b744cf83248efb96588c4d75aa3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      Validate metric               DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       val_acc_epoch             0.7744144201278687\n",
      "  val_boundary_loss_epoch      5.015075203118613e-06\n",
      "val_cross_entropy_loss_epoch     0.5853334665298462\n",
      "       val_loss_epoch            0.5853334665298462\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from run_experiment import run_expriment\n",
    "import random\n",
    "import string\n",
    "\n",
    "#Comment this lines for relu\n",
    "\n",
    "\n",
    "# activation = 'relu'\n",
    "# enable_boundary_loss = False\n",
    "# disable_batchnorm_grad_clip_exclusion = True\n",
    "# lambda_penalty = -1\n",
    "# gradient_clip_val = None\n",
    "\n",
    "\n",
    "\n",
    "activation = 'poly'\n",
    "enable_boundary_loss = True\n",
    "disable_batchnorm_grad_clip_exclusion = False\n",
    "lambda_penalty = 10\n",
    "gradient_clip_val = 1.0\n",
    "\n",
    "\n",
    "pol_degree = 4\n",
    "\n",
    "pol_degree_map = {\n",
    "    2:{\"B\": 13, \"penalty_B\": 13},\n",
    "    4:{\"B\": 20, \"penalty_B\": 20 * 0.75},\n",
    "    8:{\"B\": 35, \"penalty_B\": 35 * 0.5},\n",
    "}\n",
    "\n",
    "max_epoch = 10\n",
    "dropout = 0.0\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "project_name = \"test\"\n",
    "data_workers = 4\n",
    "model = \"mlp\"\n",
    "dataset = {\n",
    "    \"train\": train_set,\n",
    "    \"val\": val_set,\n",
    "    \"test\": test_set\n",
    "}\n",
    "\n",
    "run_id = \"test_mlp\"\n",
    "custom_tag = \"test\"\n",
    "\n",
    "ori_activaiton = \"relu\"\n",
    "samp_size = 100\n",
    "\n",
    "B = pol_degree_map[pol_degree][\"B\"]\n",
    "penalty_B = pol_degree_map[pol_degree][\"penalty_B\"]\n",
    "\n",
    "\n",
    "optimizer_params = {\n",
    "        'type': 'adamw',\n",
    "        'lr': learning_rate,\n",
    "        'params': {\n",
    "        }\n",
    "}\n",
    "scheduler_params = {'type': 'reduce_on_plateau',\n",
    "                        'params': {\n",
    "                                'mode': 'min',\n",
    "                                'factor': 0.1,\n",
    "                                'patience': 5,\n",
    "                                'threshold': 0.1,\n",
    "                                'verbose': True\n",
    "                        },\n",
    "                        'monitor': 'val_acc_epoch'\n",
    "}\n",
    "boundary_loss_params = {'type': 'exp', 'penalty_B':  penalty_B, 'acc_norm': 'sum'}\n",
    "learnable_coeffs = True\n",
    "input_size = X_train.shape[1]\n",
    "\n",
    "boundary_loss_params = {'type': 'exp', 'penalty_B': B * 1.0, 'acc_norm': 'sum'}\n",
    "actvation_params =  {\n",
    "        \"ori_activation\": ori_activaiton,\n",
    "        'B': B,\n",
    "        'samp_size': samp_size,\n",
    "        'pol_degree': pol_degree,\n",
    "        'learnable_coeffs': learnable_coeffs,\n",
    "        'initialization': \"least_square\",\n",
    "        'boundary_loss_params': boundary_loss_params\n",
    "\n",
    "    }\n",
    "num_classes = np.unique(y_train).shape[0]\n",
    "model_params = {\n",
    "    \"use_singleton_activation\": False,\n",
    "    \"bn_before_act\": False,\n",
    "    \"activation\": activation,\n",
    "    \"dropout\": dropout,\n",
    "    \"num_classes\":num_classes,\n",
    "    \"actvation_params\": actvation_params,\n",
    "    \"model\":model,\n",
    "    \"input_size\": input_size,\n",
    "    'hidden_dims': [256, 128, 64, 32, 16]\n",
    "}\n",
    "\n",
    "training_params = {\n",
    "    \"enable_boundary_loss\": enable_boundary_loss,\n",
    "    \"gradient_clip_val\": gradient_clip_val,\n",
    "    \"max_epoch\": max_epoch,\n",
    "    \"lambda_penalty\": lambda_penalty,\n",
    "    \"disable_batchnorm_grad_clip_exclusion\":disable_batchnorm_grad_clip_exclusion,\n",
    "    'optimizer_params': optimizer_params,\n",
    "    'scheduler_params': scheduler_params\n",
    "\n",
    "}\n",
    "\n",
    "dataset_params = {\n",
    "    \"data_workers\": data_workers,\n",
    "    \"dataset\": dataset,\n",
    "    \"batch_size\": 800\n",
    "}\n",
    "\n",
    "project_params = {\"run_id\": run_id,\n",
    "                  \"project_name\": project_name,\n",
    "                  \"custom_tag\": custom_tag\n",
    "                  }\n",
    "\n",
    "run_expriment(project_params=project_params, dataset_params=dataset_params,\n",
    "               model_params=model_params, training_params=training_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
